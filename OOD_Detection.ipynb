{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VANILLA (Training without Energy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS\n",
    "This block imports all essential libraries for data handling, image preprocessing, model building, and training using PyTorch and torchvision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T20:41:59.168528Z",
     "iopub.status.busy": "2025-07-22T20:41:59.168222Z",
     "iopub.status.idle": "2025-07-22T20:42:06.718356Z",
     "shell.execute_reply": "2025-07-22T20:42:06.717439Z",
     "shell.execute_reply.started": "2025-07-22T20:41:59.168502Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Pacchetti base\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torch.utils.data import DataLoader, Subset, Dataset\n",
    "\n",
    "# Utilità\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLOBALS\n",
    "This section sets the random seed for reproducibility, selects the computing device (GPU or CPU), defines dataset paths, and sets key training parameters like batch size, learning rate, and number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T20:56:45.677151Z",
     "iopub.status.busy": "2025-07-22T20:56:45.676868Z",
     "iopub.status.idle": "2025-07-22T20:56:45.685396Z",
     "shell.execute_reply": "2025-07-22T20:56:45.684704Z",
     "shell.execute_reply.started": "2025-07-22T20:56:45.677131Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Riproducibilità\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Path dataset\n",
    "dataset_root = \"/kaggle/input/food101/food-101\"\n",
    "images_root = os.path.join(dataset_root, \"images\")\n",
    "train_txt = os.path.join(dataset_root, \"meta\", \"train.txt\")\n",
    "test_txt  = os.path.join(dataset_root, \"meta\", \"test.txt\")\n",
    "\n",
    "# Batch size\n",
    "batch_size = 64\n",
    "\n",
    "# Iperparametri\n",
    "LR_ID_INIT = 2e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "EPOCHS_ID = 20\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UTILS\n",
    "This block defines all the key functions for splitting your dataset and calculating OOD detection scores. First, it implements load_indices(...), which reads file paths from .txt files and matches them to your dataset to construct precise training and testing subsets. Then, it defines two score functions decorated with @torch.no_grad() to disable gradient tracking — one computing *energy scores* via log‑sum‑exp over model logits, and the other computing *Maximum Softmax Probability (MSP)* to estimate model confidence. Together, these components streamline dataset splitting and enable efficient scoring for out‑of‑distribution evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T20:42:28.055328Z",
     "iopub.status.busy": "2025-07-22T20:42:28.054747Z",
     "iopub.status.idle": "2025-07-22T20:42:28.062135Z",
     "shell.execute_reply": "2025-07-22T20:42:28.061280Z",
     "shell.execute_reply.started": "2025-07-22T20:42:28.055302Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Carica indici da file .txt\n",
    "def load_indices(txt_file, dataset):\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        lines = f.read().splitlines()\n",
    "    idxs = []\n",
    "    for rel_path in lines:\n",
    "        for i, (img_path, _) in enumerate(dataset.samples):\n",
    "            if rel_path in img_path:\n",
    "                idxs.append(i)\n",
    "                break\n",
    "    return idxs\n",
    "\n",
    "# Funzioni per OOD detection\n",
    "def _images_from(batch):\n",
    "    return batch[0] if isinstance(batch, (list, tuple)) else batch\n",
    "\n",
    "@torch.no_grad()\n",
    "def energy_scores(loader, T):\n",
    "    out = []\n",
    "    for batch in loader:\n",
    "        x = _images_from(batch).to(device, non_blocking=True)\n",
    "        out.append((-torch.logsumexp(model(x) / T, 1)).cpu())\n",
    "    return torch.cat(out).numpy()\n",
    "\n",
    "@torch.no_grad()\n",
    "def msp_scores(loader):\n",
    "    out = []\n",
    "    for batch in tqdm(loader, desc=\"MSP\", leave=False):\n",
    "        x = _images_from(batch).to(device, non_blocking=True)\n",
    "        out.append(torch.softmax(model(x), dim=1).max(1).values.cpu())\n",
    "    return torch.cat(out).numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA\n",
    "This block prepares all datasets and loaders used in training and evaluation. It defines rich data augmentation transformations for the training set and standard preprocessing for validation and test sets. The Food-101 dataset is loaded using ImageFolder, and training, validation, and test splits are built using file-based indices and a stratified shuffle split. Corresponding DataLoader objects are created for each subset. Finally, an out-of-distribution dataset (SVHN) is loaded with the same preprocessing as the test set, enabling later evaluation of the model's OOD detection capability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T20:42:51.211507Z",
     "iopub.status.busy": "2025-07-22T20:42:51.211216Z",
     "iopub.status.idle": "2025-07-22T20:56:03.712456Z",
     "shell.execute_reply": "2025-07-22T20:56:03.711588Z",
     "shell.execute_reply.started": "2025-07-22T20:42:51.211484Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Trasformazioni\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(0.2, 0.2, 0.2),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.RandomPerspective(0.2, p=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "    transforms.RandomErasing(p=0.3, scale=(0.02, 0.2), ratio=(0.3, 3.3), value='random')\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Dataset completo\n",
    "full_dataset_train = ImageFolder(root=images_root, transform=train_transform)\n",
    "full_dataset_eval  = ImageFolder(root=images_root, transform=test_transform)\n",
    "print(f\"Dataset totale: {len(full_dataset_train)} immagini, {len(full_dataset_train.classes)} classi\")\n",
    "\n",
    "# Indici train/test da file\n",
    "train_indices = load_indices(train_txt, full_dataset_train)\n",
    "test_indices  = load_indices(test_txt, full_dataset_train)\n",
    "print(f\"Train indices: {len(train_indices)} — Test indices: {len(test_indices)}\")\n",
    "\n",
    "# Split stratificato train/val\n",
    "val_split = 0.1\n",
    "train_labels = [full_dataset_train.samples[i][1] for i in train_indices]\n",
    "splitter = StratifiedShuffleSplit(n_splits=1, test_size=val_split, random_state=42)\n",
    "train_idx, val_idx = next(splitter.split(train_indices, train_labels))\n",
    "\n",
    "# Subset con trasformazioni corrette\n",
    "train_id = Subset(full_dataset_train, [train_indices[i] for i in train_idx])\n",
    "val_id   = Subset(full_dataset_eval,  [train_indices[i] for i in val_idx])\n",
    "test_id  = Subset(full_dataset_eval,  test_indices)\n",
    "print(f\"Subset creati — Train: {len(train_id)}, Val: {len(val_id)}, Test: {len(test_id)}\")\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_id, batch_size=batch_size, shuffle=True,  num_workers=2, pin_memory=True)\n",
    "val_loader   = DataLoader(val_id,   batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "test_loader  = DataLoader(test_id,  batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "# Dataset OOD (SVHN)\n",
    "class UnlabeledImageDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.image_paths = [os.path.join(image_dir, fname)\n",
    "                            for fname in os.listdir(image_dir)\n",
    "                            if fname.endswith(\".png\")]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "# Percorso SVHN\n",
    "svhn_path = \"/kaggle/input/street-view-house-numbers/test/test\"\n",
    "\n",
    "# SVHN loader\n",
    "ood_transform = test_transform\n",
    "svhn_dataset = UnlabeledImageDataset(svhn_path, transform=ood_transform)\n",
    "svhn_loader  = DataLoader(svhn_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"SVHN dataset caricato con {len(svhn_dataset)} immagini\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *NETWORK*\n",
    "This block defines and builds a custom ResNet-50 model for Food-101 classification. It optionally loads pretrained weights and replaces the final fully connected layer with a dropout followed by a linear layer to output 101 classes. The model is then moved to the selected device (CPU or GPU) and returned for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T20:56:22.886158Z",
     "iopub.status.busy": "2025-07-22T20:56:22.885525Z",
     "iopub.status.idle": "2025-07-22T20:56:23.340499Z",
     "shell.execute_reply": "2025-07-22T20:56:23.339869Z",
     "shell.execute_reply.started": "2025-07-22T20:56:22.886133Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def build_resnet50_food101(\n",
    "        num_classes: int = 101,\n",
    "        pretrained: bool = True,\n",
    "        dropout_p: float = 0.3,\n",
    "        device: torch.device | str = None\n",
    ") -> nn.Module:\n",
    "    # Carica ResNet50\n",
    "    weights = ResNet50_Weights.DEFAULT if pretrained else None\n",
    "    model = resnet50(weights=weights)\n",
    "\n",
    "    # Sostituisce il classificatore finale\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Dropout(dropout_p),\n",
    "        nn.Linear(model.fc.in_features, num_classes)\n",
    "    )\n",
    "\n",
    "    # Invio su device\n",
    "    if device is not None:\n",
    "        model = model.to(device)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Costruzione modello\n",
    "model = build_resnet50_food101(device=device)\n",
    "\n",
    "# Verifica struttura\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN\n",
    "Train the ResNet-50 model on the Food-101 dataset. It uses cross-entropy loss with label smoothing and an Adam optimizer. The learning rate is halved every 5 epochs. For each epoch, the model is set to training mode, and performance metrics (loss and accuracy) are tracked and printed using a progress bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T20:56:52.433227Z",
     "iopub.status.busy": "2025-07-22T20:56:52.432515Z",
     "iopub.status.idle": "2025-07-22T21:08:44.867010Z",
     "shell.execute_reply": "2025-07-22T21:08:44.866188Z",
     "shell.execute_reply.started": "2025-07-22T20:56:52.433200Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Loss e ottimizzatore\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR_ID_INIT, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "print(f\"Learning rate iniziale: {LR_ID_INIT:.1e}\")\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(EPOCHS_ID):\n",
    "\n",
    "    # Dimezza il LR ogni 5 epoche\n",
    "    if epoch > 0 and epoch % 5 == 0:\n",
    "        for g in optimizer.param_groups:\n",
    "            g[\"lr\"] *= 0.5\n",
    "        print(f\"LR aggiornato: {optimizer.param_groups[0]['lr']:.1e}\")\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS_ID} — campioni: {len(train_loader.dataset)}\")\n",
    "\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    loop = tqdm(train_loader, leave=False)\n",
    "    for images, labels in loop:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Statistiche batch\n",
    "        running_loss += loss.item()\n",
    "        total += labels.size(0)\n",
    "        correct += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "        loop.set_postfix(\n",
    "            loss=running_loss / (loop.n + 1),\n",
    "            acc=100.0 * correct / total\n",
    "        )\n",
    "\n",
    "    print(f\"Train accuracy: {100.0 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUATION\n",
    "First evaluates the model’s accuracy on the in-distribution Food-101 test set. It then computes OOD detection scores using both the energy-based method and softmax confidence. These scores are used to build ROC and precision-recall curves, and to calculate key metrics: AUROC (area under ROC), FPR\\@95 (false positive rate when TPR = 95%), and AUPR (area under precision-recall curve). The results help quantify how well the model distinguishes in-distribution data from OOD examples like SVHN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T21:09:02.543146Z",
     "iopub.status.busy": "2025-07-22T21:09:02.542563Z",
     "iopub.status.idle": "2025-07-22T21:17:13.852424Z",
     "shell.execute_reply": "2025-07-22T21:17:13.851665Z",
     "shell.execute_reply.started": "2025-07-22T21:09:02.543116Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    roc_auc_score, roc_curve, precision_recall_curve,\n",
    "    average_precision_score\n",
    ")\n",
    "\n",
    "# Accuracy sul test set ID\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader, desc=\"Test\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        preds = outputs.argmax(1)\n",
    "        total += labels.size(0)\n",
    "        correct += (preds == labels).sum().item()\n",
    "\n",
    "print(f\"Test accuracy (Food-101): {100.0 * correct / total:.2f}%\")\n",
    "\n",
    "# OOD detection — Energy e Softmax\n",
    "T = 0.2\n",
    "\n",
    "id_energy  = energy_scores(test_loader, T)\n",
    "ood_energy = energy_scores(svhn_loader,  T)\n",
    "id_msp     = msp_scores(test_loader)\n",
    "ood_msp    = msp_scores(svhn_loader)\n",
    "\n",
    "# Shift e label\n",
    "m            = np.percentile(id_energy, 95)\n",
    "id_energy_s  = id_energy - m\n",
    "ood_energy_s = ood_energy - m\n",
    "energy_cat   = -np.concatenate([id_energy_s, ood_energy_s])  # score più alti = ID\n",
    "labels       = np.concatenate([np.ones_like(id_energy_s), np.zeros_like(ood_energy_s)])\n",
    "\n",
    "# Metriche AUROC / FPR@95 / AUPR\n",
    "auroc_energy = roc_auc_score(labels, energy_cat)\n",
    "auroc_msp    = roc_auc_score(labels, np.concatenate([id_msp, ood_msp]))\n",
    "\n",
    "fpr_e, tpr_e, _ = roc_curve(labels, energy_cat)\n",
    "fpr_s, tpr_s, _ = roc_curve(labels, np.concatenate([id_msp, ood_msp]))\n",
    "\n",
    "tau_energy   = 0.0\n",
    "tau_msp      = np.percentile(id_msp, 5)\n",
    "fpr95_energy = (ood_energy_s > tau_energy).mean()\n",
    "fpr95_msp    = (ood_msp > tau_msp).mean()\n",
    "\n",
    "pr_e, rc_e, _ = precision_recall_curve(labels, energy_cat)\n",
    "pr_s, rc_s, _ = precision_recall_curve(labels, np.concatenate([id_msp, ood_msp]))\n",
    "\n",
    "aupr_e = average_precision_score(labels, energy_cat)\n",
    "aupr_m = average_precision_score(labels, np.concatenate([id_msp, ood_msp]))\n",
    "\n",
    "# Risultati\n",
    "print(\"\\nMetriche OOD (ID = Food-101, OOD = SVHN):\")\n",
    "print(f\"AUROC       (Energy):   {auroc_energy:.4f}\")\n",
    "print(f\"AUROC       (Softmax):  {auroc_msp:.4f}\")\n",
    "print(f\"FPR@95TPR   (Energy):   {fpr95_energy*100:.2f}%\")\n",
    "print(f\"FPR@95TPR   (Softmax):  {fpr95_msp*100:.2f}%\")\n",
    "print(f\"AUPR (In)   (Energy):   {aupr_e:.4f}\")\n",
    "print(f\"AUPR (In)   (Softmax):  {aupr_m:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plots of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T21:17:44.917704Z",
     "iopub.status.busy": "2025-07-22T21:17:44.917410Z",
     "iopub.status.idle": "2025-07-22T21:17:46.448766Z",
     "shell.execute_reply": "2025-07-22T21:17:46.447864Z",
     "shell.execute_reply.started": "2025-07-22T21:17:44.917684Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Curve ROC e PR\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(fpr_e, tpr_e, label=f\"Energy (AUROC={auroc_energy:.4f})\", linewidth=2)\n",
    "plt.plot(fpr_s, tpr_s, label=f\"MSP    (AUROC={auroc_msp:.4f})\", linewidth=2)\n",
    "plt.plot([0, 1], [0, 1], \"--\", color=\"gray\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC — OOD Detection\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(rc_e, pr_e, label=f\"Energy (AUPR={aupr_e:.4f})\", linewidth=2)\n",
    "plt.plot(rc_s, pr_s, label=f\"MSP    (AUPR={aupr_m:.4f})\", linewidth=2)\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Istogrammi Energy e MSP\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "axes[0].hist(id_energy_s,  bins=80, alpha=0.6, label=\"ID\", color=\"steelblue\")\n",
    "axes[0].hist(ood_energy_s, bins=80, alpha=0.6, label=\"OOD\", color=\"orange\")\n",
    "axes[0].axvline(0, color=\"black\", linestyle=\"--\")\n",
    "axes[0].set_title(\"Distribuzione Energy (shiftato)\")\n",
    "axes[0].set_xlabel(\"Energy\")\n",
    "axes[0].set_ylabel(\"Frequenza\")\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].hist(id_msp,  bins=80, alpha=0.6, label=\"ID\", color=\"green\")\n",
    "axes[1].hist(ood_msp, bins=80, alpha=0.6, label=\"OOD\", color=\"red\")\n",
    "axes[1].axvline(tau_msp, color=\"black\", linestyle=\"--\")\n",
    "axes[1].set_title(\"Distribuzione Max Softmax\")\n",
    "axes[1].set_xlabel(\"Max Softmax\")\n",
    "axes[1].set_ylabel(\"Frequenza\")\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USE OF FOOD PACKAGING \n",
    "\n",
    "This code defines a custom dataset class to load unlabeled images from a directory structure, applying standard preprocessing transformations. It prepares the Food Packaging dataset to be used as OOD (Out-Of-Distribution) input, using the same normalization and resizing steps as the in-distribution test set (Food-101). Finally, it wraps the dataset in a DataLoader for efficient batch processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T21:18:09.983867Z",
     "iopub.status.busy": "2025-07-22T21:18:09.983571Z",
     "iopub.status.idle": "2025-07-22T21:20:14.253771Z",
     "shell.execute_reply": "2025-07-22T21:20:14.253133Z",
     "shell.execute_reply.started": "2025-07-22T21:18:09.983845Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Trasformazione come nel test set ID (Food-101)\n",
    "ood_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Dataset senza etichette\n",
    "class UnlabeledImageDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.image_paths = []\n",
    "        for root, _, files in os.walk(image_dir):\n",
    "            for fname in files:\n",
    "                if fname.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "                    self.image_paths.append(os.path.join(root, fname))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "# ✅ Percorso corretto alla directory con le immagini\n",
    "foodpack_path = \"/kaggle/input/fooddatasert/resize_data(150)/resize_data(1~50)\"\n",
    "\n",
    "# DataLoader\n",
    "foodpack_dataset = UnlabeledImageDataset(foodpack_path, transform=ood_transform)\n",
    "foodpack_loader = DataLoader(foodpack_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"✔️ Dataset Food Packaging caricato con {len(foodpack_dataset)} immagini.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script evaluates the model's ability to detect out-of-distribution (OOD) data using both the Energy score and Maximum Softmax Probability (MSP). First, it computes the final classification accuracy on the in-distribution test set (Food-101). Then, it calculates energy and softmax-based scores for both ID and OOD samples (Food Packaging). Using these scores, it computes standard OOD metrics like AUROC, FPR\\@95TPR, and AUPR. Finally, it visualizes performance through ROC and PR curves, and plots the distributions of the energy and softmax scores to show the separation between ID and OOD data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T21:20:24.974478Z",
     "iopub.status.busy": "2025-07-22T21:20:24.974099Z",
     "iopub.status.idle": "2025-07-22T21:37:28.687094Z",
     "shell.execute_reply": "2025-07-22T21:37:28.686240Z",
     "shell.execute_reply.started": "2025-07-22T21:20:24.974451Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, roc_curve, precision_recall_curve,\n",
    "    average_precision_score\n",
    ")\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "# 1. Accuracy finale sul test set ID (Food-101)\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    test_loop = tqdm(test_loader, total=len(test_loader), desc=\"Testing\")\n",
    "    for images, labels in test_loop:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"\\n🧪 Final Test Accuracy (Food-101): {100 * correct / total:.2f}%\")\n",
    "\n",
    "# 2. OOD Detection — ENERGY & MSP\n",
    "T = 0.2\n",
    "PLOT_HIST = True\n",
    "\n",
    "def _images_from(batch):\n",
    "    return batch[0] if isinstance(batch, (list, tuple)) else batch\n",
    "\n",
    "@torch.no_grad()\n",
    "def energy_scores(loader, T):\n",
    "    out = []\n",
    "    for batch in loader:\n",
    "        x = _images_from(batch).to(device, non_blocking=True)\n",
    "        out.append((-torch.logsumexp(model(x) / T, 1)).cpu())\n",
    "    return torch.cat(out).numpy()\n",
    "\n",
    "@torch.no_grad()\n",
    "def msp_scores(loader):\n",
    "    out = []\n",
    "    for batch in tqdm(loader, desc=\"MSP\", leave=False):\n",
    "        x = _images_from(batch).to(device, non_blocking=True)\n",
    "        out.append(torch.softmax(model(x), dim=1).max(1).values.cpu())\n",
    "    return torch.cat(out).numpy()\n",
    "\n",
    "# 3. Calcolo score\n",
    "id_energy  = energy_scores(test_loader, T)\n",
    "ood_energy = energy_scores(foodpack_loader,  T)\n",
    "id_msp     = msp_scores(test_loader)\n",
    "ood_msp    = msp_scores(foodpack_loader)\n",
    "\n",
    "# 4. m-shift & label\n",
    "m            = np.percentile(id_energy, 95)\n",
    "id_energy_s  = id_energy - m\n",
    "ood_energy_s = ood_energy - m\n",
    "energy_cat   = -np.concatenate([id_energy_s, ood_energy_s])  # più alto = ID\n",
    "labels       = np.concatenate([np.ones_like(id_energy_s), np.zeros_like(ood_energy_s)])\n",
    "\n",
    "# 5. Metriche\n",
    "auroc_energy = roc_auc_score(labels, energy_cat)\n",
    "auroc_msp    = roc_auc_score(labels, np.concatenate([id_msp, ood_msp]))\n",
    "\n",
    "fpr_e, tpr_e, _ = roc_curve(labels, energy_cat)\n",
    "fpr_s, tpr_s, _ = roc_curve(labels, np.concatenate([id_msp, ood_msp]))\n",
    "\n",
    "tau_energy   = 0.0\n",
    "tau_msp      = np.percentile(id_msp, 5)\n",
    "fpr95_energy = (ood_energy_s > tau_energy).mean()\n",
    "fpr95_msp    = (ood_msp > tau_msp).mean()\n",
    "\n",
    "pr_e, rc_e, _ = precision_recall_curve(labels, energy_cat)\n",
    "pr_s, rc_s, _ = precision_recall_curve(labels, np.concatenate([id_msp, ood_msp]))\n",
    "\n",
    "aupr_e = average_precision_score(labels, energy_cat)\n",
    "aupr_m = average_precision_score(labels, np.concatenate([id_msp, ood_msp]))\n",
    "\n",
    "# 6. Stampa risultati\n",
    "print(\"\\n📊  METRICHE OOD  (ID = Food-101,  OOD = Food Packaging)\")\n",
    "print(f\"• AUROC  (Energy)      : {auroc_energy:.4f}\")\n",
    "print(f\"• AUROC  (Soft-max)    : {auroc_msp:.4f}\")\n",
    "print(f\"• FPR@95TPR (Energy)   : {fpr95_energy*100:.2f}%\")\n",
    "print(f\"• FPR@95TPR (Soft-max) : {fpr95_msp*100:.2f}%\")\n",
    "print(f\"• AUPR-In (Energy)     : {aupr_e:.4f}\")\n",
    "print(f\"• AUPR-In (Soft-max)   : {aupr_m:.4f}\")\n",
    "\n",
    "# 7. ROC & PR Curve\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# ROC\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(fpr_e, tpr_e, linewidth=2.2, label=f\"Energy (AUROC={auroc_energy:.4f})\")\n",
    "plt.plot(fpr_s, tpr_s, linewidth=2.2, label=f\"MSP   (AUROC={auroc_msp:.4f})\")\n",
    "plt.plot([0, 1], [0, 1], \"--\", color=\"gray\", linewidth=1.5)\n",
    "plt.xlabel(\"False Positive Rate\", fontsize=12)\n",
    "plt.ylabel(\"True Positive Rate\", fontsize=12)\n",
    "plt.title(\"ROC — OOD Detection\", fontsize=14)\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True)\n",
    "\n",
    "# PR\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(rc_e, pr_e, linewidth=2.2, label=f\"Energy (AUPR={aupr_e:.4f})\")\n",
    "plt.plot(rc_s, pr_s, linewidth=2.2, label=f\"MSP   (AUPR={aupr_m:.4f})\")\n",
    "plt.xlabel(\"Recall\", fontsize=12)\n",
    "plt.ylabel(\"Precision\", fontsize=12)\n",
    "plt.title(\"Precision-Recall\", fontsize=14)\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 8. Istogrammi\n",
    "if PLOT_HIST:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "    axes[0].hist(id_energy_s,  bins=80, alpha=0.6, label=\"ID (Food-101)\", color=\"#1f77b4\")\n",
    "    axes[0].hist(ood_energy_s, bins=80, alpha=0.6, label=\"OOD (Food Packaging)\", color=\"#ff7f0e\")\n",
    "    axes[0].axvline(0, color=\"k\", ls=\"--\", linewidth=1.5)\n",
    "    axes[0].set_title(\"Distribuzione Energy Score (shiftato)\", fontsize=13)\n",
    "    axes[0].set_xlabel(\"Energy\", fontsize=11)\n",
    "    axes[0].set_ylabel(\"Frequenza\", fontsize=11)\n",
    "    axes[0].legend(fontsize=10)\n",
    "\n",
    "    axes[1].hist(id_msp,  bins=80, alpha=0.6, label=\"ID (Food-101)\", color=\"#2ca02c\")\n",
    "    axes[1].hist(ood_msp, bins=80, alpha=0.6, label=\"OOD (Food Packaging)\", color=\"#d62728\")\n",
    "    axes[1].axvline(tau_msp, color=\"k\", ls=\"--\", linewidth=1.5)\n",
    "    axes[1].set_title(\"Distribuzione Max Softmax\", fontsize=13)\n",
    "    axes[1].set_xlabel(\"Max Softmax\", fontsize=11)\n",
    "    axes[1].set_ylabel(\"Frequenza\", fontsize=11)\n",
    "    axes[1].legend(fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROBUST (Training with Energy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT\n",
    "This section imports all the necessary libraries for the project, including PyTorch for deep learning, torchvision for dataset and model utilities, and scikit-learn for data splitting. It also includes utility packages like NumPy for numerical operations, Matplotlib for plotting, and tqdm for progress bars.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Librerie base\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "# Torchvision\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torchvision import transforms\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# Altre\n",
    "from tqdm.notebook import tqdm\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLOBALS\n",
    "\n",
    "This block sets the random seed for reproducibility, configures the computing device (CPU or GPU), defines dataset paths, and initializes several key hyperparameters for Outlier Exposure (OE) training—such as margin thresholds, loss coefficients, learning rate, early stopping, and number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Seed e device\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device attivo: {device}\")\n",
    "\n",
    "# Parametri dataset\n",
    "dataset_root = \"/kaggle/input/food101/food-101\"\n",
    "images_root = os.path.join(dataset_root, \"images\")\n",
    "train_txt = os.path.join(dataset_root, \"meta\", \"train.txt\")\n",
    "test_txt  = os.path.join(dataset_root, \"meta\", \"test.txt\")\n",
    "\n",
    "# Hyperparametri OE\n",
    "M_IN, M_OUT     = -6.0, -0.5\n",
    "LAMBDA_MAX      = 0.06\n",
    "ALPHA_ID        = 0.05\n",
    "WARMUP_EP       = 3\n",
    "RAMP_EP         = 2\n",
    "PATIENCE        = 6\n",
    "TEMPERATURE     = 1.0\n",
    "EPOCHS_OE       = 20\n",
    "PRINT_EVERY     = 100\n",
    "LR_OE_INIT      = 1e-4\n",
    "WEIGHT_DECAY    = 1e-4\n",
    "BATCH_SIZE      = 64\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UTILS\n",
    "\n",
    "This section defines utility functions for handling dataset indices and computing energy-based scores. It includes a function to extract sample indices from .txt metadata files and two functions related to energy-based Outlier Exposure (OE): one to compute energy from model logits, and another that implements the energy regularization loss. This loss penalizes in-distribution samples with energy above a margin and out-of-distribution samples with energy below a threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Carica indici da file .txt\n",
    "def load_indices(txt_file, dataset):\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        lines = f.read().splitlines()\n",
    "    idxs = []\n",
    "    for rel_path in lines:\n",
    "        for i, (img_path, _) in enumerate(dataset.samples):\n",
    "            if rel_path in img_path:\n",
    "                idxs.append(i)\n",
    "                break\n",
    "    return idxs\n",
    "\n",
    "# Energy score da logits\n",
    "def compute_energy(logits, T=1.0):\n",
    "    return -T * torch.logsumexp(logits / T, dim=1)\n",
    "\n",
    "# Funzione di loss OE (energy-based)\n",
    "def energy_regularization_loss(logits_id, logits_ood, m_in=-6.0, m_out=-1.0, lambda_energy=0.1, T=1.0):\n",
    "    energy_id = compute_energy(logits_id, T)\n",
    "    energy_ood = compute_energy(logits_ood, T)\n",
    "    loss_id = torch.mean(torch.clamp(energy_id - m_in, min=0)**2)\n",
    "    loss_ood = torch.mean(torch.clamp(m_out - energy_ood, min=0)**2)\n",
    "    return lambda_energy * (loss_id + loss_ood)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA\n",
    "\n",
    "This code prepares the Food-101 dataset for training, validation, and testing. It defines two sets of image transformations: one with heavy data augmentation for training, and another simpler one for evaluation. It then loads the full dataset and uses pre-defined text files to extract train/test indices. A stratified split is performed on the training set to create a validation subset. Finally, `DataLoader`s are initialized for each subset to efficiently feed data during training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Trasformazioni\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(0.2, 0.2, 0.2),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.RandomPerspective(0.2, p=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225]),\n",
    "    transforms.RandomErasing(p=0.3, scale=(0.02, 0.2), ratio=(0.3, 3.3), value='random')\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Dataset completo\n",
    "full_dataset_train = ImageFolder(images_root, transform=train_transform)\n",
    "full_dataset_eval  = ImageFolder(images_root, transform=test_transform)\n",
    "\n",
    "train_indices = load_indices(train_txt, full_dataset_train)\n",
    "test_indices  = load_indices(test_txt, full_dataset_train)\n",
    "\n",
    "# Split stratificato\n",
    "val_split = 0.1\n",
    "train_labels = [full_dataset_train.samples[i][1] for i in train_indices]\n",
    "splitter = StratifiedShuffleSplit(n_splits=1, test_size=val_split, random_state=42)\n",
    "train_idx, val_idx = next(splitter.split(train_indices, train_labels))\n",
    "\n",
    "# Subset\n",
    "train_id = Subset(full_dataset_train, [train_indices[i] for i in train_idx])\n",
    "val_id   = Subset(full_dataset_eval,  [train_indices[i] for i in val_idx])\n",
    "test_id  = Subset(full_dataset_eval,  test_indices)\n",
    "\n",
    "# Dataloader\n",
    "train_loader = DataLoader(train_id, batch_size=BATCH_SIZE, shuffle=True,  num_workers=2, pin_memory=True)\n",
    "val_loader   = DataLoader(val_id,   batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "test_loader  = DataLoader(test_id,  batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NETWORK\n",
    "\n",
    "This code defines and initializes a custom ResNet-50 model for the Food-101 classification task. It loads pretrained weights (if specified) and replaces the original fully connected layer with a new head composed of a dropout layer followed by a linear layer that outputs predictions for 101 food classes. The model is then moved to the specified computation device (CPU or GPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "def build_resnet50_food101(\n",
    "        num_classes=101,\n",
    "        pretrained=True,\n",
    "        dropout_p=0.3,\n",
    "        device=None\n",
    ") -> nn.Module:\n",
    "    weights = ResNet50_Weights.DEFAULT if pretrained else None\n",
    "    model = resnet50(weights=weights)\n",
    "\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Dropout(dropout_p),\n",
    "        nn.Linear(model.fc.in_features, num_classes)\n",
    "    )\n",
    "\n",
    "    return model.to(device) if device else model\n",
    "\n",
    "model = build_resnet50_food101(device=device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN OE\n",
    "\n",
    "This code implements the full fine-tuning process of the ResNet-50 model using Outlier Exposure (OE) and an energy-based regularization strategy. It defines an Adam optimizer and a cosine annealing scheduler to adjust the learning rate across epochs. During training, the model minimizes a loss composed of a cross-entropy term on in-distribution (ID) samples and an energy-based term that encourages the model to assign lower energy to ID and higher energy to OOD (out-of-distribution) samples. A dynamic λ is used to gradually increase the contribution of the OE loss (after a warm-up and ramp-up phase), while label smoothing is progressively reduced. After each epoch, the model is evaluated on a validation set, and early stopping is applied based on validation loss improvements. The best model weights are saved during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "\n",
    "# Ottimizzatore e scheduler\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR_OE_INIT, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=2, eta_min=1e-6)\n",
    "\n",
    "# Loss functions\n",
    "label_smooth = 0.1\n",
    "criterion_id  = nn.CrossEntropyLoss(label_smoothing=label_smooth)\n",
    "criterion_val = nn.CrossEntropyLoss()\n",
    "\n",
    "# Energy function (per comodità)\n",
    "def energy(logits, T=TEMPERATURE):\n",
    "    return -T * torch.logsumexp(logits / T, dim=1)\n",
    "\n",
    "# Stato per early stopping\n",
    "best_val_loss = float(\"inf\")\n",
    "best_wts      = copy.deepcopy(model.state_dict())\n",
    "no_improve    = 0\n",
    "\n",
    "for epoch in range(EPOCHS_OE):\n",
    "    # Calcolo λ dinamico (warmup + ramp-up)\n",
    "    if epoch < WARMUP_EP:\n",
    "        lam = 0.0\n",
    "    elif epoch < WARMUP_EP + RAMP_EP:\n",
    "        lam = LAMBDA_MAX * (epoch - WARMUP_EP + 1) / RAMP_EP\n",
    "    else:\n",
    "        lam = LAMBDA_MAX\n",
    "\n",
    "    # Aggiorna label smoothing dopo warmup+ramp\n",
    "    if epoch >= WARMUP_EP + RAMP_EP and label_smooth > 0:\n",
    "        label_smooth = max(0.0, label_smooth - 0.05)\n",
    "        criterion_id.label_smoothing = label_smooth\n",
    "\n",
    "    print(f\"\\nEpoch {epoch+1}/{EPOCHS_OE} | λ={lam:.3f} | LR={optimizer.param_groups[0]['lr']:.2e} | LS={label_smooth:.2f}\")\n",
    "\n",
    "    # Train\n",
    "    model.train()\n",
    "    ood_iter = iter(svhn_loader)\n",
    "    run_gap = correct = total = 0\n",
    "\n",
    "    for i, (x_id, y_id) in enumerate(train_loader):\n",
    "        try:\n",
    "            x_ood = next(ood_iter)\n",
    "        except StopIteration:\n",
    "            ood_iter = iter(svhn_loader)\n",
    "            x_ood = next(ood_iter)\n",
    "\n",
    "        x_id, y_id, x_ood = x_id.to(device), y_id.to(device), x_ood.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        logits_id  = model(x_id)\n",
    "        logits_ood = model(x_ood)\n",
    "\n",
    "        # CE + OE loss\n",
    "        loss_ce = criterion_id(logits_id, y_id)\n",
    "        e_id  = energy(logits_id)\n",
    "        e_ood = energy(logits_ood)\n",
    "        gap   = (e_ood.mean() - e_id.mean()).item()\n",
    "\n",
    "        loss_id  = torch.clamp(e_id - M_IN, min=0).pow(2).mean()\n",
    "        loss_ood = torch.clamp(M_OUT - e_ood, min=0).pow(2).mean()\n",
    "        loss_oe  = lam * (loss_ood + ALPHA_ID * loss_id)\n",
    "        loss = loss_ce + loss_oe\n",
    "\n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Statistiche\n",
    "        run_gap += gap\n",
    "        correct += (logits_id.argmax(1) == y_id).sum().item()\n",
    "        total   += y_id.size(0)\n",
    "\n",
    "        if (i+1) % PRINT_EVERY == 0 or (i+1) == len(train_loader):\n",
    "            print(f\"batch {i+1:4d} | gap={gap:4.2f} | CE={loss_ce.item():.3f} | OE={loss_oe.item():.3f}\")\n",
    "\n",
    "    train_acc = 100 * correct / total\n",
    "    print(f\"Train accuracy: {train_acc:.2f}% — mean gap: {run_gap/len(train_loader):.2f}\")\n",
    "\n",
    "    # Validazione\n",
    "    model.eval()\n",
    "    val_loss = val_correct = val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            out = model(x.to(device))\n",
    "            val_loss  += criterion_val(out, y.to(device)).item()\n",
    "            val_correct += (out.argmax(1) == y.to(device)).sum().item()\n",
    "            val_total   += y.size(0)\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_acc   = 100 * val_correct / val_total\n",
    "    print(f\"Val loss: {val_loss:.4f} — accuracy: {val_acc:.2f}%\")\n",
    "\n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss - 1e-4:\n",
    "        best_val_loss = val_loss\n",
    "        best_wts = copy.deepcopy(model.state_dict())\n",
    "        torch.save(best_wts, \"best_model_weights.pth\")\n",
    "        no_improve = 0\n",
    "        print(\"Model salvato.\")\n",
    "    else:\n",
    "        no_improve += 1\n",
    "        print(f\"Nessun miglioramento ({no_improve}/{PATIENCE})\")\n",
    "        if no_improve >= PATIENCE:\n",
    "            print(\"Early stopping attivato.\")\n",
    "            break\n",
    "\n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUATION\n",
    "This final evaluation block loads the best model weights obtained during training and recalibrates the BatchNorm statistics using the training set. It then computes the energy scores and maximum softmax probabilities (MSP) for both in-distribution (Food-101) and out-of-distribution (SVHN) samples. After shifting the energy scores using the 95th percentile of the ID distribution, the script evaluates the model's OOD detection performance using standard metrics: AUROC, FPR\\@95TPR, and AUPR. Results are reported for both the energy-based and softmax-based methods, providing a comprehensive assessment of the model's ability to distinguish ID from OOD data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Carica i migliori pesi e ricalibra BatchNorm\n",
    "model.load_state_dict(best_wts)\n",
    "model.train()\n",
    "with torch.no_grad():\n",
    "    for x, _ in DataLoader(train_id, batch_size=256, shuffle=False):\n",
    "        _ = model(x.to(device))\n",
    "model.eval()\n",
    "print(\"Pesi migliori caricati. BatchNorm ricalibrato.\")\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve, average_precision_score\n",
    "\n",
    "@torch.no_grad()\n",
    "def energy_scores(loader, T=TEMPERATURE):\n",
    "    model.eval()\n",
    "    scores = []\n",
    "    for x in loader:\n",
    "        x = x.to(device)\n",
    "        logits = model(x)\n",
    "        scores.append(compute_energy(logits, T).cpu())\n",
    "    return torch.cat(scores).numpy()\n",
    "\n",
    "@torch.no_grad()\n",
    "def msp_scores(loader):\n",
    "    model.eval()\n",
    "    scores = []\n",
    "    for x in loader:\n",
    "        x = x.to(device)\n",
    "        logits = model(x)\n",
    "        softmax = torch.softmax(logits, dim=1)\n",
    "        scores.append(softmax.max(1).values.cpu())\n",
    "    return torch.cat(scores).numpy()\n",
    "\n",
    "# Score ID e OOD\n",
    "id_energy  = energy_scores(test_loader)\n",
    "ood_energy = energy_scores(svhn_loader)\n",
    "id_msp     = msp_scores(test_loader)\n",
    "ood_msp    = msp_scores(svhn_loader)\n",
    "\n",
    "# Energy shift\n",
    "m = np.percentile(id_energy, 95)\n",
    "id_energy_s  = id_energy - m\n",
    "ood_energy_s = ood_energy - m\n",
    "energy_cat   = -np.concatenate([id_energy_s, ood_energy_s])\n",
    "labels       = np.concatenate([np.ones_like(id_energy_s), np.zeros_like(ood_energy_s)])\n",
    "\n",
    "# MSP concat\n",
    "msp_cat = np.concatenate([id_msp, ood_msp])\n",
    "\n",
    "# AUROC e FPR@95\n",
    "auroc_energy = roc_auc_score(labels, energy_cat)\n",
    "auroc_msp    = roc_auc_score(labels, msp_cat)\n",
    "\n",
    "tau_energy   = 0.0\n",
    "tau_msp      = np.percentile(id_msp, 5)\n",
    "fpr95_energy = (ood_energy_s > tau_energy).mean()\n",
    "fpr95_msp    = (ood_msp > tau_msp).mean()\n",
    "\n",
    "# AUPR\n",
    "pr_e, rc_e, _ = precision_recall_curve(labels, energy_cat)\n",
    "pr_s, rc_s, _ = precision_recall_curve(labels, msp_cat)\n",
    "aupr_e = average_precision_score(labels, energy_cat)\n",
    "aupr_m = average_precision_score(labels, msp_cat)\n",
    "\n",
    "# Risultati\n",
    "print(\"\\nValutazione OOD (ID = Food-101, OOD = SVHN)\")\n",
    "print(f\"AUROC        (Energy):   {auroc_energy:.4f}\")\n",
    "print(f\"AUROC        (Softmax):  {auroc_msp:.4f}\")\n",
    "print(f\"FPR@95TPR    (Energy):   {fpr95_energy*100:.2f}%\")\n",
    "print(f\"FPR@95TPR    (Softmax):  {fpr95_msp*100:.2f}%\")\n",
    "print(f\"AUPR (in)    (Energy):   {aupr_e:.4f}\")\n",
    "print(f\"AUPR (in)    (Softmax):  {aupr_m:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ROC + PR + Histograms\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# ROC\n",
    "fpr_e, tpr_e, _ = roc_curve(labels, energy_cat)\n",
    "fpr_s, tpr_s, _ = roc_curve(labels, msp_cat)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(fpr_e, tpr_e, label=f\"Energy (AUROC = {auroc_energy:.4f})\", linewidth=2)\n",
    "plt.plot(fpr_s, tpr_s, label=f\"Softmax (AUROC = {auroc_msp:.4f})\", linewidth=2)\n",
    "plt.plot([0, 1], [0, 1], \"--\", color=\"gray\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# PR\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(rc_e, pr_e, label=f\"Energy (AUPR = {aupr_e:.4f})\", linewidth=2)\n",
    "plt.plot(rc_s, pr_s, label=f\"Softmax (AUPR = {aupr_m:.4f})\", linewidth=2)\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Histograms\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "# Energy histogram\n",
    "axes[0].hist(id_energy_s,  bins=80, alpha=0.6, label=\"ID\", color=\"steelblue\")\n",
    "axes[0].hist(ood_energy_s, bins=80, alpha=0.6, label=\"OOD\", color=\"orange\")\n",
    "axes[0].axvline(0, color=\"black\", linestyle=\"--\")\n",
    "axes[0].set_title(\"Distribuzione Energy Score (shiftato)\")\n",
    "axes[0].set_xlabel(\"Energy\")\n",
    "axes[0].set_ylabel(\"Frequenza\")\n",
    "axes[0].legend()\n",
    "\n",
    "# MSP histogram\n",
    "axes[1].hist(id_msp,  bins=80, alpha=0.6, label=\"ID\", color=\"green\")\n",
    "axes[1].hist(ood_msp, bins=80, alpha=0.6, label=\"OOD\", color=\"red\")\n",
    "axes[1].axvline(tau_msp, color=\"black\", linestyle=\"--\")\n",
    "axes[1].set_title(\"Distribuzione Max Softmax\")\n",
    "axes[1].set_xlabel(\"Score\")\n",
    "axes[1].set_ylabel(\"Frequenza\")\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 26161,
     "sourceId": 33368,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1791699,
     "sourceId": 2922769,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5460175,
     "sourceId": 9055466,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
